# Rule-Based PDF Metadata & Nanomaterial Extraction

**Rule-based + Optional Ollama (LLM-Hybrid)**

This project extracts structured information from scientific PDF papers, with a focus on:

    - Paper metadata
    - Nanomaterial identity

The pipeline is designed with a rule-based core and an optional LLM refinement layer using Ollama.

    âœ… Rule-based extraction is the default and fully deterministic
    âš ï¸ LLM support is optional, experimental, and used only as a refinement layer

-------------------

## What this pipeline extracts (rule-based)

**Paper metadata**

- Title (layout-aware, font-size based)

- Year

- DOI

- Source URL (if present in PDF)

- Article type
(`review`, `in vitro`, `in vivo`, `field`, `modelling`, `method`)

- Author-provided keywords (cleaned, bounded, no paragraph leakage)

- MeSH / indexed keywords (only if explicitly present in PDF text)

**Nanomaterial identity**
- Core composition(s)
(Ag, Au, TiOâ‚‚, ZnO, CNT, graphene, SiOâ‚‚, nanoplastics, MOF, liposomes, etc.)

- Nanomaterial category
(`metal`, `metal_oxide`, `carbon`, `silica`, `polymer_plastic`, `quantum_dot`, `mof`, `nanocellulose`, `liposome`, `other`)

- Physical phase / polymorph
(anatase, rutile, brookite)
- Crystallinity (textual or percentage if stated)
- Reproducibility identifiers:

    - CAS number

    - Catalog / batch / lot number (validated, no false matches)

----------------
## Project structure

```text
keyword_extractor/
â”‚
â”œâ”€â”€ run.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ extract/
â”‚   â”œâ”€â”€ cli.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â””â”€â”€ runner.py
â”‚   â”‚
â”‚   â”œâ”€â”€ io/
â”‚   â”‚   â”œâ”€â”€ pdf_reader.py
â”‚   â”‚   â””â”€â”€ excel_writer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ extractors/
â”‚   â”‚   â”œâ”€â”€ metadata.py
â”‚   â”‚   â””â”€â”€ nanomaterial.py
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ ollama_client.py        # LLM refinement (PATCH-based)
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ merge.py                # PATCH + merge logic
â”‚       â””â”€â”€ sectioning.py           # Abstract / keyword hints
â”‚
â””â”€â”€ pdfs/


```

## Installation

1. Create and activate a virtual environment (recommended)
```bash
python -m venv .venv
```

windows
```bash
.venv\Scripts\activate
```
MacOS/Linux
```bash
source .venv/bin/activate
```

2. Install dependencies
```bash
pip install -r requirements.txt
```

`requirements.txt`
```bash
pymupdf
pandas
openpyxl

requests
```

## How to run (rule-based only)

Basic usage:
```bash
python run.py --pdf_dir ./pdfs
```

Optional flags
```bash
python run.py \
  --pdf_dir ./pdfs \
  --max_pages 3 \
  --excel results.xlsx
```

- `--pdf_dir` : directory containing PDFs

- `--max_pages` : number of pages used for metadata (default: 3)

- `--excel` : output Excel file path


### Optional: LLM-Hybrid mode with Ollama
#### 5.1 What the LLM is used for (important)
The LLM does NOT replace rule-based extraction.
Instead, the pipeline works as:
```bash
Rules â†’ Structured baseline
      â†’ LLM produces a PATCH (only confident fields)
      â†’ PATCH is merged into rules
```
âœ… Hybrid output can only improve or correct fields

âŒ Hybrid output can never remove rule-based information

#### 5.2 Install Ollama
Download and install Ollama:
ğŸ‘‰ https://ollama.com

#### 5.3 Pull a recommended model
I used `qwen2.5:7b`, feel free to use any model that suits your project.

```bash
ollama pull qwen2.5:7b
```
Alternatives:
- `mistral-large:123b` (better accuracy if hardware allows)
- `llama3.1:8b` (more stable)

#### 5.4 Run pipeline with LLM refinement
```bash
python run.py \
  --pdf_dir ./pdfs \
  --llm \
  --llm_model qwen2.5:7b
```

## Current limitations (known & expected)
- Tables are not yet parsed as structured tables
- Images are not OCRed
- MeSH terms only extracted if explicitly present
- LLM refinement is experimental and may be disabled safely
